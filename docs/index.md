---
layout: default
title: Home
nav_order: 1
description: "LLM4S - Large Language Models for Scala. A comprehensive, type-safe framework for building LLM-powered applications."
permalink: /
---

# LLM4S - Large Language Models for Scala
{: .fs-9 }

A comprehensive, type-safe framework for building LLM-powered applications in Scala.
{: .fs-6 .fw-300 }

[Get Started](/getting-started/installation){: .btn .btn-primary .fs-5 .mb-4 .mb-md-0 .mr-2 }
[View on GitHub](https://github.com/llm4s/llm4s){: .btn .fs-5 .mb-4 .mb-md-0 }

---

## Why LLM4S?

LLM4S brings the power of large language models to the Scala ecosystem with a focus on **type safety**, **functional programming**, and **production readiness**.

```scala
import org.llm4s.llmconnect.LLMConnect
import org.llm4s.llmconnect.model.UserMessage

// Simple LLM call with automatic provider selection
val result = for {
  client <- LLMConnect.create()
  response <- client.complete(
    messages = List(UserMessage("Explain quantum computing")),
    model = None  // Uses configured model
  )
} yield response

result match {
  case Right(completion) => println(completion.content)
  case Left(error) => println(s"Error: $error")
}
```

---

## Key Features

### üîå Multi-Provider Support
Connect seamlessly to **OpenAI**, **Anthropic**, **Azure OpenAI**, and **Ollama** with a unified API. Switch providers with a single environment variable.

[Learn more ‚Üí](/guide/basic-usage)

### ü§ñ Agent Framework
Build sophisticated single and multi-agent workflows with built-in tool calling, conversation management, and state persistence.

[Explore agents ‚Üí](/guide/agents)

### üõ†Ô∏è Type-Safe Tool Calling
Define tools with automatic schema generation and type-safe execution. Supports both local tools and Model Context Protocol (MCP) servers.

[See examples ‚Üí](/examples/tools)

### üí¨ Multi-Turn Conversations
Functional, immutable conversation management with automatic context window pruning and conversation persistence.

[View patterns ‚Üí](/guide/multi-turn)

### üîç RAG & Embeddings
Built-in support for retrieval-augmented generation with vector embeddings and semantic search.

[Get started ‚Üí](/guide/embeddings)

### üìä Observability
Comprehensive tracing with Langfuse integration for debugging, monitoring, and production analytics.

[Learn more ‚Üí](/guide/observability)

### üñºÔ∏è Multimodal Support
Generate and analyze images, convert speech-to-text and text-to-speech, and work with multiple content modalities.

[Image generation ‚Üí](/guide/image-generation) | [Speech ‚Üí](/guide/speech)

### üê≥ Secure Execution
Containerized workspace for safe tool execution with Docker isolation.

[Advanced topics ‚Üí](/advanced/workspace)

---

## Quick Start

### Installation

Add LLM4S to your `build.sbt`:

```scala
libraryDependencies += "org.llm4s" %% "llm4s-core" % "0.1.0-SNAPSHOT"
```

### Configuration

Set your API key and model:

```bash
export LLM_MODEL=openai/gpt-4o
export OPENAI_API_KEY=sk-...
```

### Your First Program

```scala
import org.llm4s.llmconnect.LLMConnect
import org.llm4s.llmconnect.model._

object HelloLLM extends App {
  val result = for {
    client <- LLMConnect.create()
    response <- client.complete(
      messages = List(
        SystemMessage("You are a helpful assistant."),
        UserMessage("What is Scala?")
      ),
      model = None
    )
  } yield response.content

  result.fold(
    error => println(s"Error: $error"),
    content => println(s"Response: $content")
  )
}
```

[Complete installation guide ‚Üí](/getting-started/installation)

---

## Example Gallery

Explore **46 working examples** covering all features:

<div class="code-example" markdown="1">

**Basic Examples**
- [Basic LLM Calling](/examples/basic#basic-llm-calling) - Simple conversations
- [Streaming Responses](/examples/basic#streaming) - Real-time token streaming
- [Multi-Provider](/examples/basic#multi-provider) - OpenAI, Anthropic, Ollama

**Agent Examples**
- [Single-Step Agent](/examples/agents#single-step) - Manual control
- [Multi-Turn Conversations](/examples/agents#multi-turn) - Functional conversation API
- [Conversation Persistence](/examples/agents#persistence) - Save and resume

**Tool Examples**
- [Weather Tool](/examples/tools#weather) - Simple tool definition
- [Multi-Tool Agent](/examples/tools#multi-tool) - Multiple tools coordination
- [MCP Integration](/examples/tools#mcp) - External tool servers

</div>

[Browse all examples ‚Üí](/examples/)

---

## Documentation

<div class="grid">
  <div class="grid-item">
    <h3>üìñ User Guide</h3>
    <p>Comprehensive guides for all features</p>
    <a href="/guide/basic-usage">Start learning ‚Üí</a>
  </div>

  <div class="grid-item">
    <h3>üíª Examples</h3>
    <p>46 working code examples</p>
    <a href="/examples/">Browse examples ‚Üí</a>
  </div>

  <div class="grid-item">
    <h3>üöÄ Advanced Topics</h3>
    <p>Production readiness & optimization</p>
    <a href="/advanced/production">Learn more ‚Üí</a>
  </div>

  <div class="grid-item">
    <h3>üìö API Reference</h3>
    <p>Complete API documentation</p>
    <a href="/api/llm-client">View API docs ‚Üí</a>
  </div>
</div>

---

## Why Scala for LLMs?

<div class="highlight-box">

‚úÖ **Type Safety** - Catch errors at compile time, not in production

‚úÖ **Functional Programming** - Immutable data and pure functions for predictable systems

‚úÖ **JVM Ecosystem** - Access to mature, production-grade libraries

‚úÖ **Concurrency** - Advanced models for safe, efficient parallelism

‚úÖ **Performance** - JVM speed with functional elegance

‚úÖ **Enterprise Ready** - Seamless integration with JVM systems

</div>

---

## Community

- **Discord**: [Join our community](https://discord.gg/4uvTPn6qww)
- **GitHub**: [llm4s/llm4s](https://github.com/llm4s/llm4s)
- **Starter Kit**: [llm4s.g8](https://github.com/llm4s/llm4s.g8)
- **License**: Apache 2.0

---

## Project Status

LLM4S is under active development. Current focus:

- ‚úÖ **Phase 1.0**: Core framework and multi-provider support
- ‚úÖ **Phase 1.1**: Functional conversation management
- üöß **Phase 1.2**: Guardrails and safety framework
- üìã **Phase 1.3**: Multi-agent handoff mechanism

[View roadmap ‚Üí](/reference/roadmap)

---

## Getting Help

- **Documentation**: Browse the [user guide](/guide/basic-usage)
- **Examples**: Check out [working examples](/examples/)
- **Discord**: Ask questions in our [community](https://discord.gg/4uvTPn6qww)
- **Issues**: Report bugs on [GitHub](https://github.com/llm4s/llm4s/issues)

---

**Ready to get started?** [Install LLM4S ‚Üí](/getting-started/installation)
